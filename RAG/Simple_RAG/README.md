

 Simple RAG Project â€” README

A minimal Retrieval-Augmented Generation (RAG) starter using **LangChain**, **ChromaDB**, and **Ollama** running the **Llama 3.2** model locally.

## Overview
This project demonstrates:
1. Document ingestion & embeddings  
2. Vector storage with ChromaDB  
3. Retrieval with LangChain  
4. Local LLM inference using Ollama (Llama 3.2)

## Features
- Fully local workflow  
- Uses LangChain + ChromaDB  
- Runs Llama 3.2 with Ollama  
- Lightweight and easy to extend
